---
layout: index
title: Home
---

# An Open Source AutoML Benchmark

This the homepage for the open and extensible AutoML Benchmark.
The AutoML Benchmark provides an overview and comparison of open-source AutoML systems.
It is *open* because the benchmark infrastructure is [open-source](https://github.com/openml/automlbenchmark/)
and *extensible* because you can [add your own](extending.md) problems and datasets.

A brief overview and further references for each AutoML system can be found on the [AutoML systems](automl_overview.md) page.
For a thorough explanation of the benchmark, and evaluation of results, you can read our [paper](paper.md).
If you want to analyze the results yourself, you can do this on the [results](results.md) pages.

Because the benchmark infrastructure is open-source, you can rerun the benchmark yourself, use custom datasets or your own AutoML platform as explained in our [project documentation](documentation.md).
We also invite you to [submit your own AutoML](documentation.md) system to be evaluated against the benchmark and included in the overview.
